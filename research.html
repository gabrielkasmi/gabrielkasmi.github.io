<!doctype html>
<html>
  <head>
  	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-133810388-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-133810388-1');
	</script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Research | Gabriel Kasmi</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  
  <body>
    <div class="wrapper">
      <header>
        <h1 class="title">Research</h1>
        <!-- Add other header elements as needed -->
        <ul>
          <li><a href="#Current">Current research</a></li>
          <li><a href="#Publications">Publications</a></li>
          <li><a href="#Peer">Peer review</a></li>
          <li><a href="#Misc">Other works</a></li>

          <li><a href="phd_thesis.html">PhD Thesis</a></li>
          <li><a href="misc.html">Oldies</a></li>
          
          <li><a href="index.html">Back to home</a></li>
       </ul>
      </header>
      <section> 

        <h2 id="Current">Current research</h2>

        <h3>Explainability and signal processing</h3>

        <p>
          My first topic of interest is to improve our understanding of deep learning models. In computer vision, 
          current methods focus on assessing where model focus on input images. However, these approaches
          are uninformative when it comes to explain why classification models can fail to correctly predict 
          some instances.
        </p>

        <p>
          My research consists in using tools from classical signal processins theory, in particular the wavelet
          transform, to meaningfully decompose the input image and then to identify the important parts of this 
          decomposition into the model's prediction. I prefer using the wavelet transform over the Fourier transform
          as the wavelet decomposition of an image is localized in space and in frequency, which on images 
          enables to assess where and what (scales) models see. 
        </p>

        <p>
          During the PhD thesis, we introduced the <a href="https://openreview.net/forum?id=112o4j4VCY">wavelet scale attribution method (WCAM)</a>, 
          an extension of <a href="https://openreview.net/forum?id=hA-PHQGOjqQ">Fel's et. al.</a> attribution method
          to the wavelet domain in order to assess what models see on an image. Scales of the wavelet transform correspond to 
          structural components of the image: therefore, we can assess whether the model relies on shapes, textures or other 
          intermediary components to make its prediction. 
        </p>

        <p>
          I believe that the the WCAM can be expanded into several interesting directions:
          <ul>
            <li>
              First, it can be expanded to 1D signals such as sounds,
            </li>
            <li>
              Second, I believe that there can be interesting connections between the scale decomposition 
              obtained with the WCAM and recent concept-based XAI approaches such as <a href="https://arxiv.org/abs/2211.10154">CRAFT</a>.   
            </li>
            <li>
              Finally, the scales of the wavelet transform are localized in frequency, and several works (see for instance this 
              <a href="https://openreview.net/forum?id=rQ1cNbi07Vq">work</a> or 
              this <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Amplitude-Phase_Recombination_Rethinking_Robustness_of_Convolutional_Neural_Networks_in_Frequency_ICCV_2021_paper.html">one</a>) leveraged
              frequency-based methods to characterize and analyze the robustness of models to various input perturbations. 
            </li>
          </ul>

          Feel free to reach me if you are interested in collaborating!
        </p>

        <h3>Improving the observability of rooftop PV systems</h3>

        <p>
          The photovoltaic (PV) installed capacity grows very quickly, both worldwide and in France. 
          A specificity of PV energy is that a sizezable share of the systems are located on rooftops (20% of the installed capacity in France).
          These rooftop systems are not well known by authorities or transmission system operators. 
          The main goal of my thesis was to look for methods to improve the knowledge regarding the rooftop PV fleet and ultimately to introduce
          new methods for accurately estimating the PV power production.
        </p>

        <p>
          In the thesis, we've introduced a method for constructing a large scale registry of rooftop PV systems 
          and demonstrated that we could estimate the rooftop PV power production with relatively few information 
          on these systems. 
        </p>

        <p>
          The last chapter of the thesis raises a lot of questions for improving current methods for PV power estimation,
          in particular since the task of fairly comparing the proposed method with the TSO current practices is very challenging. 
          I also have in mind potential applications beyond France, for instance in coutries where the share of small scale PV is 
          higher than in France.
        </p>

        <h2 id="Publications">List of publications</h2>

        <h3>Publications in peer-reviewed journals</h3>

        <ul>
          <li>
            Kasmi, G., Saint-Drenan, Y. M., Trebosc, D., Jolivet, R., Leloux, J., Sarr, B., & Dubus, L. (2023). 
            A crowdsourced dataset of aerial images with annotated 
            solar photovoltaic arrays and installation metadata. <i>Scientific Data 10</i>(1), 59.
          </li>
        </ul>

        <p>
          <b>Abstract</b>:
          Photovoltaic (PV) energy generation plays a crucial role in the energy 
          transition. Small-scale, rooftop PV installations are deployed at an unprecedented 
          pace, and their safe integration into the grid requires up-to-date, high-quality 
          information. Overhead imagery is increasingly being used to improve the knowledge 
          of rooftop PV installations with machine learning models capable of automatically 
          mapping these installations. However, these models cannot be reliably transferred 
          from one region or imagery source to another without incurring a decrease in accuracy. 
          To address this issue, known as distribution shift, and foster the development of PV array 
          mapping pipelines, we propose a dataset containing aerial images, segmentation masks, and 
          installation metadata (i.e., technical characteristics). We provide installation metadata 
          for more than 28000 installations. We supply ground truth segmentation masks for 13000 
          installations, including 7000 with annotations for two different image providers. Finally, 
          we provide installation metadata that matches the annotation for more than 8000 installations. 
          Dataset applications include end-to-end PV registry construction, robust PV installations 
          mapping, and analysis of crowdsourced datasets. The article can be accessed <a href="https://www.nature.com/articles/s41597-023-01951-4">here</a> and the 
          Zenodo repository containing the dataset by clicking here:
          <a href="https://doi.org/10.5281/zenodo.7358126"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.7358126.svg" alt="DOI"></a>.
        </p>
        
        <ul>
          <li>
            Kasmi, G.; Touron, A.; Blanc, P.; Saint-Drenan, Y.-M.; Fortin, M.; Dubus, L. (2024)
            Remote-Sensing-Based Estimation of Rooftop Photovoltaic Power Production Using Physical Conversion Models and Weather Data.
            <i>Energies 17</i>(17), 4353.
          </li>
        </ul>

        <p>
          <b>Abstract</b>:
          The global photovoltaic (PV) installed capacity, vital for the electric sector’s decarbonation, 
          reached 1552.3 GWp in 2023. In France, the capacity stood at 19.9 GWp in April 2024. 
          The growth of the PV installed capacity over a year was nearly 32% worldwide and 15.7% in France. 
          However, integrating PV electricity into grids is hindered by poor knowledge of 
          rooftop PV systems, constituting 20% of France’s installed capacity, and the lack of 
          measurements of the production stemming from these systems. This problem of lack of 
          measurements of the rooftop PV power production is referred to as the lack of 
          observability. Using ground-truth measurements of individual PV systems, available 
          at an unprecedented temporal and spatial scale, we show that by estimating the PV 
          power production of an individual rooftop system by combining solar irradiance and 
          temperature data, the characteristics of the PV system inferred from remote sensing 
          methods and an irradiation-to-electric power conversion model provides accurate estimations 
          of the PV power production. We report an average estimation error (measured with the pRMSE) 
          of 10% relative to the system size. Our study shows that we can improve rooftop PV 
          observability, and thus its integration into the electric grid, using little information 
          on these systems, a simple model of the PV system, and weather data. More broadly, this 
          study shows that limited information is sufficient to derive a reasonably good estimation 
          of the PV power production of small-scale systems.. The article can be accessed <a href="https://doi.org/10.3390/en17174353">here</a>.
        </p>

        <h3>Workshops (peer reviewed)</h3>

        <ul>
          <li>
            Kasmi, G., Dubus, L., Saint-Drenan, Y. M., & Blanc, P. (2023). 
            Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to 
            the Wavelet Domain. <i>In XAI in Action: Past, Present, and Future Applications</i>.
            <a href="https://openreview.net/forum?id=112o4j4VCY">Link</a>.
          </li>
          <li>
            Kasmi, G., Dubus, L., Saint-Drenan, Y. M., & Blanc, P. (2023). 
            Can We Reliably Improve the Robustness to Image Acquisition of Remote 
            Sensing of PV Systems?. <i>In Tackling Climate Change with Machine Learning 
              workshop at NeurIPS 2023</i>.
              <a href="https://arxiv.org/abs/2309.12214">Link</a>.
          </li>
          <li>
            Kasmi, G., Dubus, L., Blanc, P., & Saint-Drenan, Y. M. (2022). 
            Towards unsupervised assessment with open-source data of the accuracy of deep 
            learning-based distributed PV mapping. <i>In MACLEAN: MAChine Learning for EArth 
              ObservatioN Workshop co-located with the European Conference on Machine 
              Learning and Principles and Practice of Knowledge Discovery in 
              Databases (ECML/PKDD 2022)</i>.
              <a href="https://arxiv.org/abs/2207.07466">Link</a>.
            </li>
        </ul>

        <h3>Oral presentations</h3>

        <ul>
          <li>
            Kasmi, G., Touron, A., Blanc, P. Saint-Drenan, Y.-M., Fortin, M.,& Dubus, L. (2023).
            Enhancing regional PV power estimation using physics-based models, solar irradiance data and deep 
            learning. <i>In International Conference in Energy and Meteorology (ICEM), Padova, Italy </i>.
            <a href="https://www.wemcouncil.org/ICEMs/ICEM2023/ICEM2023_20230628_SCROVEGNI_1400_KASMI.pdf">Slides.</a>
          </li>

          <li>
            Kasmi, G., Dubus, L., Saint-Drenan, Y. M., & Blanc, P. (2022). 
            Leveraging earth observation data and deep learning to estimate the 
            PV output in France. <i> In MACLEAN Workshop @Cap/RFIAP, Vannes, France </i>.
            <a href="https://caprfiap2022.sciencesconf.org/data/pages/pitch_kasmi.pdf">Slides</a>.
          </li>


          <li>
            Kasmi, G., Dubus, L., Saint-Drenan, Y. M., & Blanc, P. (2022). Assessment of the potential of 
            Earth observation data and deep convolutional neural networks to improve the estimation and forecast 
            of the solar power production in France.
            <i> PVPS Tasks 16 experts meeting, 2022, Sophia-Antipolis, France.</i>
          </li>
        </ul>

        <h3>Preprints</h3>


        <ul>
          <li>
            Trémenbert, Y., Kasmi, G., Dubus, L., Saint-Drenan, Y. M., & Blanc, P. (2023). 
            PyPVRoof: a Python package for extracting the characteristics of rooftop PV 
            installations using remote sensing data. <i>arXiv preprint arXiv:2309.07143</i>.
            <a href="https://arxiv.org/abs/2309.07143">Link</a>.
          </li>
        </ul>

        <h3>Posters</h3>

        <ul>
          <li>
            Kasmi, G., Dubus, L., Saint-Drenan, Y. M., & Blanc, P. (2022). Assessment of the potential of 
            Earth observation data and deep convolutional neural networks to improve the estimation and 
            forecast of the solar power production in France.
            <i>In 4th MADICS Symposium, Lyon, France</i>.
          </li>
          <li>
            Kasmi, G., Dubus, L., Saint-Drenan, Y. M., & Blanc, P. (2021). Solar Array Detection on Aerial Photography Based on Convolutional Neural Networks:
            Image of the Solar Array Characteristics and Image Backgrounds on the Out-of-domain
            Generalization. <i>
              In SophIA Summit, Sophia-Antipolis, France
            </i>.            
          </li>
        </ul>

        <h2 id="Peer">Peer review</h2>

        <h3>Journals</h3>
        <ul>
          <li><a href="https://onlinelibrary.wiley.com/journal/2367198x">Solar RRL</a></li>
          <li><a href="https://www.nature.com/sdata/">Scientific Data</a></li>
        </ul>
        <h3>Conferences</h3>
        <ul>
          <li>Ethics reviewer for the Benchmark and Datasets Track at <a href="https://neurips.cc/Conferences/2024">NeurIPS</a> 2024</li>
        </ul>
        <h3>Workshops</h3>
        <ul>
          <li><a href="https://xai-in-action.github.io/">XAI in action workshop (NeurIPS 2023)</a></li>
          <li><a href="https://www.climatechange.ai/events/iclr2024">Tackling Climate Change with Machine Learning workshop (ICLR 2024)</a></li>
          <li><a href="https://sites.google.com/view/wicv-cvpr-2024/">Women in Computer Vision workshop (ECCV 2024)</a></li>
          <li><a href="https://interpretable-ai-workshop.github.io/">Interpretable AI: Past, Present and Future workshop (NeurIPS 2024)</a></li>
        </ul>

        <h2 id="Misc">Miscellaneous works</h2>

        <ul>
          <li>Kasmi, G., Dubus, L, Saint-Drenan, Y.-M. & Blanc, P. Looking for a 
            frequency-based principle to predict 
            the sensitivity of convolutional neural networks to Gaussian image perturbations.</li>
        </ul>
        <p>
          This work in process was presented during the PhD Forum at ECML-PKDD 2022. 
          It it a snapshot of our early attempts to use Fourier theory to explain the (lack of) 
          robustness of a CNN classifier. This work later led to the WCAM. 
          The manuscript is accessible 
          <a href="https://drive.google.com/file/d/1ebLL5pKBaO2bIvoEQJCbQbala3D96d-4/view?usp=drive_link">here</a> 
          and the slides of the presentation 
          <a href="https://drive.google.com/file/d/1w84tL_hcle8P6EYiwON3A7H1RyHFOVsz/view?usp=drive_link">here</a>.  
        </p>

                    
        
      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
